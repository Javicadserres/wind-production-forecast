{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x22365a5e9f0>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from matplotlib import cm\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from pathlib import Path\n",
    "from model.losses import SmoothPinballLoss\n",
    "from model.model import AttentionLSTM\n",
    "from data.preprocessing import FrameTorch\n",
    "from model.trainer import Trainer\n",
    "from utils import get_scores\n",
    "\n",
    "torch.manual_seed(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Import data and set quantiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH_DATA = Path.cwd().parent / 'data' / 'files'\n",
    "\n",
    "data = pd.read_csv((PATH_DATA / 'data.csv'), index_col='time')\n",
    "\n",
    "# quantiles to predict\n",
    "quantiles = torch.tensor([0.025, 0.05, 0.1, 0.15, 0.85, 0.9, 0.95, 0.975])\n",
    "\n",
    "# lookback periods\n",
    "slide = 6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LSTM USING ONLY THE TARGET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "_data = pd.concat(\n",
    "    [data['production'].shift(1).copy(), data['production']], \n",
    "    axis=1, \n",
    "    keys=['production_shift', 'production']\n",
    ").dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# intialize frametorch\n",
    "frametorch = FrameTorch(_data)\n",
    "# split data\n",
    "frametorch.split_data()\n",
    "# scale data\n",
    "frametorch.scale_data(method=MinMaxScaler)\n",
    "\n",
    "# train, val and test loaders\n",
    "train_loader, val_loader, test_loader = frametorch.data_to_loader(slide=slide)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### MODEL PREPARATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# number of inputs and outputs\n",
    "n_inputs = frametorch.data.shape[1] - 1\n",
    "n_outputs = len(quantiles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model\n",
    "quantilenet = AttentionLSTM(embed_dim=n_inputs, out_size=n_outputs, hidden_size=slide, n_layers=2)\n",
    "# criterion to use\n",
    "criterion = SmoothPinballLoss(quantiles)\n",
    "# optimizer\n",
    "optimizer = optim.Adam(quantilenet.parameters(), lr=0.0001)\n",
    "# trainer class\n",
    "trainer = Trainer(quantilenet, criterion, optimizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### TRAIN DE MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0 train loss: 1.332 val loss: 1.115\n",
      "epoch: 200 train loss: 0.163 val loss: 0.158\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[1;32mIn [7]\u001b[0m, in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[0m quantilenet \u001b[38;5;241m=\u001b[39m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m      2\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m2000\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_logger\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m200\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpatience\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m50\u001b[39;49m\n\u001b[0;32m      3\u001b[0m \u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\Documents\\Javier\\Conocimiento\\Universidad\\estadistica\\wind-production-forecast\\src\\model\\trainer.py:53\u001b[0m, in \u001b[0;36mTrainer.fit\u001b[1;34m(self, train_loader, val_loader, epochs, n_logger, patience)\u001b[0m\n\u001b[0;32m     48\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_initialize_variables(\n\u001b[0;32m     49\u001b[0m         train_loader, val_loader, epochs, n_logger, patience\n\u001b[0;32m     50\u001b[0m )\n\u001b[0;32m     51\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mepoch \u001b[38;5;241m<\u001b[39m epochs \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstop: \n\u001b[0;32m     52\u001b[0m     \u001b[38;5;66;03m# training\u001b[39;00m\n\u001b[1;32m---> 53\u001b[0m     train_loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward_train\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m                \n\u001b[0;32m     54\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrain_losses\u001b[38;5;241m.\u001b[39mappend(train_loss)   \n\u001b[0;32m     56\u001b[0m     \u001b[38;5;66;03m# validation\u001b[39;00m\n",
      "File \u001b[1;32m~\\Documents\\Javier\\Conocimiento\\Universidad\\estadistica\\wind-production-forecast\\src\\model\\trainer.py:105\u001b[0m, in \u001b[0;36mTrainer.forward_train\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    102\u001b[0m loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcriterion(outputs, target)\n\u001b[0;32m    104\u001b[0m \u001b[38;5;66;03m# backward propagation and update\u001b[39;00m\n\u001b[1;32m--> 105\u001b[0m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    106\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptimizer\u001b[38;5;241m.\u001b[39mstep()    \n\u001b[0;32m    107\u001b[0m train_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m loss\u001b[38;5;241m.\u001b[39mitem()\n",
      "File \u001b[1;32m~\\Anaconda3\\envs\\tfg\\lib\\site-packages\\torch\\_tensor.py:307\u001b[0m, in \u001b[0;36mTensor.backward\u001b[1;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[0;32m    298\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    299\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[0;32m    300\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[0;32m    301\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    305\u001b[0m         create_graph\u001b[38;5;241m=\u001b[39mcreate_graph,\n\u001b[0;32m    306\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs)\n\u001b[1;32m--> 307\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\Anaconda3\\envs\\tfg\\lib\\site-packages\\torch\\autograd\\__init__.py:150\u001b[0m, in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[0;32m    146\u001b[0m inputs \u001b[38;5;241m=\u001b[39m (inputs,) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(inputs, torch\u001b[38;5;241m.\u001b[39mTensor) \u001b[38;5;28;01melse\u001b[39;00m \\\n\u001b[0;32m    147\u001b[0m     \u001b[38;5;28mtuple\u001b[39m(inputs) \u001b[38;5;28;01mif\u001b[39;00m inputs \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mtuple\u001b[39m()\n\u001b[0;32m    149\u001b[0m grad_tensors_ \u001b[38;5;241m=\u001b[39m _tensor_or_tensors_to_tuple(grad_tensors, \u001b[38;5;28mlen\u001b[39m(tensors))\n\u001b[1;32m--> 150\u001b[0m grad_tensors_ \u001b[38;5;241m=\u001b[39m \u001b[43m_make_grads\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    151\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m retain_graph \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    152\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n",
      "File \u001b[1;32m~\\Anaconda3\\envs\\tfg\\lib\\site-packages\\torch\\autograd\\__init__.py:52\u001b[0m, in \u001b[0;36m_make_grads\u001b[1;34m(outputs, grads)\u001b[0m\n\u001b[0;32m     50\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m out\u001b[38;5;241m.\u001b[39mnumel() \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m     51\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgrad can be implicitly created only for scalar outputs\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 52\u001b[0m     new_grads\u001b[38;5;241m.\u001b[39mappend(\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mones_like\u001b[49m\u001b[43m(\u001b[49m\u001b[43mout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmemory_format\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpreserve_format\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m     53\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     54\u001b[0m     new_grads\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;28;01mNone\u001b[39;00m)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "quantilenet = trainer.fit(\n",
    "    train_loader, val_loader, epochs=2000, n_logger=200, patience=50\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### USING ALL THE DATA AVAILABLE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_non_spread = data.drop(data.filter(regex='spread').columns, axis=1)\n",
    "# intialize frametorch\n",
    "frametorch_all = FrameTorch(data_non_spread)\n",
    "# split data\n",
    "frametorch_all.split_data()\n",
    "# scale data\n",
    "frametorch_all.scale_data(method=MinMaxScaler)\n",
    "\n",
    "# train, val and test loaders\n",
    "train_loader, val_loader, test_loader = frametorch_all.data_to_loader(slide=slide)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### MODEL PREPARATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# number of inputs and outputs\n",
    "n_inputs = frametorch_all.data.shape[1] - 1\n",
    "n_outputs = len(quantiles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model\n",
    "quantilenet_all = AttentionLSTM(embed_dim=n_inputs, out_size=n_outputs, hidden_size=slide, n_layers=2)\n",
    "# criterion to use\n",
    "criterion = SmoothPinballLoss(quantiles)\n",
    "# optimizer\n",
    "optimizer = optim.Adam(quantilenet_all.parameters(), lr=0.0001)\n",
    "# trainer class\n",
    "trainer_all = Trainer(quantilenet_all, criterion, optimizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### TRAIN DE MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0 train loss: 2.257 val loss: 1.623\n",
      "epoch: 2 train loss: 1.297 val loss: 0.951\n",
      "epoch: 4 train loss: 0.867 val loss: 0.581\n",
      "epoch: 6 train loss: 0.635 val loss: 0.427\n",
      "epoch: 8 train loss: 0.494 val loss: 0.349\n",
      "epoch: 10 train loss: 0.408 val loss: 0.312\n",
      "epoch: 12 train loss: 0.358 val loss: 0.295\n",
      "epoch: 14 train loss: 0.332 val loss: 0.287\n",
      "epoch: 16 train loss: 0.318 val loss: 0.284\n",
      "epoch: 18 train loss: 0.312 val loss: 0.283\n",
      "epoch: 20 train loss: 0.308 val loss: 0.282\n",
      "epoch: 22 train loss: 0.307 val loss: 0.282\n",
      "epoch: 24 train loss: 0.305 val loss: 0.281\n",
      "epoch: 26 train loss: 0.304 val loss: 0.281\n",
      "epoch: 28 train loss: 0.303 val loss: 0.281\n",
      "epoch: 30 train loss: 0.303 val loss: 0.28\n",
      "epoch: 32 train loss: 0.302 val loss: 0.28\n",
      "epoch: 34 train loss: 0.301 val loss: 0.279\n",
      "epoch: 36 train loss: 0.3 val loss: 0.279\n",
      "epoch: 38 train loss: 0.3 val loss: 0.279\n",
      "epoch: 40 train loss: 0.299 val loss: 0.278\n",
      "epoch: 42 train loss: 0.299 val loss: 0.278\n",
      "epoch: 44 train loss: 0.298 val loss: 0.278\n",
      "epoch: 46 train loss: 0.297 val loss: 0.277\n",
      "epoch: 48 train loss: 0.297 val loss: 0.277\n",
      "epoch: 50 train loss: 0.297 val loss: 0.277\n",
      "epoch: 52 train loss: 0.296 val loss: 0.277\n",
      "epoch: 54 train loss: 0.295 val loss: 0.274\n",
      "epoch: 56 train loss: 0.293 val loss: 0.271\n",
      "epoch: 58 train loss: 0.287 val loss: 0.265\n",
      "epoch: 60 train loss: 0.273 val loss: 0.246\n",
      "epoch: 62 train loss: 0.249 val loss: 0.214\n",
      "epoch: 64 train loss: 0.227 val loss: 0.197\n",
      "epoch: 66 train loss: 0.214 val loss: 0.188\n",
      "epoch: 68 train loss: 0.204 val loss: 0.185\n",
      "epoch: 70 train loss: 0.197 val loss: 0.181\n",
      "epoch: 72 train loss: 0.191 val loss: 0.174\n",
      "epoch: 74 train loss: 0.185 val loss: 0.169\n",
      "epoch: 76 train loss: 0.18 val loss: 0.166\n",
      "epoch: 78 train loss: 0.175 val loss: 0.164\n",
      "epoch: 80 train loss: 0.171 val loss: 0.162\n",
      "epoch: 82 train loss: 0.167 val loss: 0.16\n",
      "epoch: 84 train loss: 0.163 val loss: 0.158\n",
      "epoch: 86 train loss: 0.159 val loss: 0.158\n",
      "epoch: 88 train loss: 0.156 val loss: 0.157\n",
      "epoch: 90 train loss: 0.153 val loss: 0.158\n",
      "epoch: 92 train loss: 0.151 val loss: 0.158\n",
      "epoch: 94 train loss: 0.148 val loss: 0.158\n",
      "epoch: 96 train loss: 0.146 val loss: 0.155\n",
      "epoch: 98 train loss: 0.143 val loss: 0.153\n",
      "epoch: 100 train loss: 0.141 val loss: 0.152\n",
      "epoch: 102 train loss: 0.139 val loss: 0.15\n",
      "epoch: 104 train loss: 0.137 val loss: 0.151\n",
      "epoch: 106 train loss: 0.136 val loss: 0.151\n",
      "epoch: 108 train loss: 0.134 val loss: 0.152\n",
      "epoch: 110 train loss: 0.133 val loss: 0.153\n",
      "epoch: 112 train loss: 0.131 val loss: 0.152\n",
      "epoch: 114 train loss: 0.13 val loss: 0.151\n",
      "epoch: 116 train loss: 0.128 val loss: 0.149\n",
      "epoch: 118 train loss: 0.127 val loss: 0.146\n",
      "epoch: 120 train loss: 0.126 val loss: 0.142\n",
      "epoch: 122 train loss: 0.125 val loss: 0.139\n",
      "epoch: 124 train loss: 0.124 val loss: 0.136\n",
      "epoch: 126 train loss: 0.123 val loss: 0.135\n",
      "epoch: 128 train loss: 0.122 val loss: 0.134\n",
      "epoch: 130 train loss: 0.121 val loss: 0.135\n",
      "epoch: 132 train loss: 0.12 val loss: 0.137\n",
      "epoch: 134 train loss: 0.119 val loss: 0.141\n",
      "epoch: 136 train loss: 0.119 val loss: 0.145\n",
      "epoch: 138 train loss: 0.118 val loss: 0.15\n",
      "epoch: 140 train loss: 0.118 val loss: 0.153\n",
      "epoch: 142 train loss: 0.117 val loss: 0.153\n",
      "epoch: 144 train loss: 0.117 val loss: 0.149\n",
      "epoch: 146 train loss: 0.116 val loss: 0.142\n",
      "epoch: 148 train loss: 0.115 val loss: 0.133\n",
      "epoch: 150 train loss: 0.114 val loss: 0.124\n",
      "epoch: 152 train loss: 0.113 val loss: 0.12\n",
      "epoch: 154 train loss: 0.112 val loss: 0.118\n",
      "epoch: 156 train loss: 0.112 val loss: 0.117\n",
      "epoch: 158 train loss: 0.111 val loss: 0.117\n",
      "epoch: 160 train loss: 0.111 val loss: 0.118\n",
      "epoch: 162 train loss: 0.11 val loss: 0.12\n",
      "epoch: 164 train loss: 0.11 val loss: 0.126\n",
      "epoch: 166 train loss: 0.109 val loss: 0.141\n",
      "epoch: 168 train loss: 0.11 val loss: 0.167\n",
      "epoch: 170 train loss: 0.111 val loss: 0.201\n",
      "epoch: 172 train loss: 0.112 val loss: 0.214\n",
      "epoch: 174 train loss: 0.112 val loss: 0.181\n",
      "epoch: 176 train loss: 0.11 val loss: 0.131\n",
      "epoch: 178 train loss: 0.108 val loss: 0.114\n",
      "epoch: 180 train loss: 0.107 val loss: 0.119\n",
      "epoch: 182 train loss: 0.108 val loss: 0.128\n",
      "epoch: 184 train loss: 0.108 val loss: 0.124\n",
      "epoch: 186 train loss: 0.107 val loss: 0.113\n",
      "epoch: 188 train loss: 0.106 val loss: 0.118\n",
      "epoch: 190 train loss: 0.106 val loss: 0.157\n",
      "epoch: 192 train loss: 0.107 val loss: 0.208\n"
     ]
    }
   ],
   "source": [
    "quantilenet_all = trainer_all.fit(\n",
    "    train_loader, val_loader, epochs=2000, n_logger=2, patience=50\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CHECK INPUTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader, val_loader, test_loader = frametorch.data_to_loader(slide=slide)\n",
    "\n",
    "# validation input and target\n",
    "inputs, target = val_loader.dataset.inputs, val_loader.dataset.target\n",
    "y_test = pd.Series(target.squeeze().tolist())\n",
    "\n",
    "# quantilenet predictions\n",
    "y_pred_quantilenet = quantilenet(inputs)\n",
    "y_preds_quantilenet = pd.DataFrame(y_pred_quantilenet.tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Predictions without spread"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader, val_loader, test_loader = frametorch_all.data_to_loader(slide=slide)\n",
    "\n",
    "# validation input and target\n",
    "inputs, _ = val_loader.dataset.inputs, val_loader.dataset.target\n",
    "\n",
    "# quantilenet predictions\n",
    "y_pred_quantilenet_all = quantilenet_all(inputs)\n",
    "y_preds_quantilenet_all = pd.DataFrame(y_pred_quantilenet_all.tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### COMPARE MODEL TYPES"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convergence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_ss = pd.Series(trainer.train_losses[1:])\n",
    "validations_losses_ss = pd.Series(trainer.val_losses)\n",
    "\n",
    "loss_ss_all = pd.Series(trainer_all.train_losses[1:])\n",
    "validations_losses_ss_all = pd.Series(trainer_all.val_losses)\n",
    "\n",
    "fig, ax = plt.subplots(ncols=2, figsize=(15, 5), sharey=True)\n",
    "\n",
    "loss_ss.plot(ax=ax[0])\n",
    "loss_ss_all.plot(ax=ax[0])\n",
    "validations_losses_ss.plot(ax=ax[1])\n",
    "validations_losses_ss_all.plot(ax=ax[1])\n",
    "\n",
    "ax[0].set_ylabel('Loss')\n",
    "ax[0].set_title('Train Loss per epoch')\n",
    "ax[0].legend(['Only target', 'All data'])\n",
    "ax[0].grid()\n",
    "\n",
    "ax[1].set_title('Validation Loss per epoch')\n",
    "ax[1].legend(['Only target', 'All data'])\n",
    "ax[1].grid()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "quantilenet_scores = get_scores(y_pred_quantilenet, target, quantiles)\n",
    "quantilenet_all_scores = get_scores(y_pred_quantilenet_all, target, quantiles)\n",
    "\n",
    "final_scores = pd.concat(\n",
    "    [quantilenet_scores, quantilenet_all_scores], axis=1, keys=['Only target', 'All data']\n",
    ")\n",
    "final_scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "viridis = cm.get_cmap('viridis', len(quantiles))\n",
    "fig, ax = plt.subplots(ncols=2, figsize=(20, 5), sharey=True)\n",
    "\n",
    "for i in range(len(y_preds_quantilenet_all.columns)-1):\n",
    "    ax[0].fill_between(\n",
    "        y_preds_quantilenet_all.index[:200], \n",
    "        y_preds_quantilenet_all[i][:200], \n",
    "        y_preds_quantilenet_all[i+1][:200], \n",
    "        color=viridis.colors[i]\n",
    "    )  \n",
    "y_test[:200].plot(color='red', ax=ax[0])\n",
    "ax[0].set_title('Predictions using all data')\n",
    "ax[0].grid()\n",
    "\n",
    "for i in range(len(y_preds_quantilenet.columns)-1):\n",
    "    ax[1].fill_between(\n",
    "        y_preds_quantilenet.index[:200], \n",
    "        y_preds_quantilenet[i][:200], \n",
    "        y_preds_quantilenet[i+1][:200], \n",
    "        color=viridis.colors[i]\n",
    "    )\n",
    "y_test[:200].plot(color='red', ax=ax[1])\n",
    "ax[1].set_title('Predictions with just the label as an input')\n",
    "ax[1].grid()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "3bf7057b3dc3018a3df2d3471e55c40fe4c6f235c33790920dc2d668d496996a"
  },
  "kernelspec": {
   "display_name": "tfg",
   "language": "python",
   "name": "tfg"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
